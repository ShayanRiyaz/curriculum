<!--title={Merge Sort Time Complexity}-->

<!--badges={Algorithms:10,Python:5}-->

<!--concepts={Merge sort}-->

Merge sort is similar to Insertion sort in that it all 3 cases have the same time complexity. Again, here is the code for the algorithm as a reference:

```Python
def mergeSort(alist):
    if len(alist) > 1:
        mid = len(alist) // 2 # integer division
        lefthalf = alist[:mid]
        righthalf = alist[mid:]
        mergeSort(lefthalf)
        mergeSort(righthalf)

        i = 0
        j = 0
        k = 0
        while i < len(lefthalf) and j < len(righthalf):
        	if lefthalf[i] <= righthalf[j]:
        		alist[k]=lefthalf[i]
        		i=i+1
        	else:
        		alist[k]=righthalf[j]
        		j=j+1
        	k=k+1

        while i < len(lefthalf):
        	alist[k]=lefthalf[i]
        	i=i+1
        	k=k+1

        while j < len(righthalf):
        	alist[k]=righthalf[j]
        	j=j+1
        	k=k+1


```

Merge sort's time complexity for all 3 cases is O(nlogn). 

###Where does Log n come from?

The logn in the time complexity comes from the recursion that is happening 2 lines below the first if statement:

```python
def mergeSort(alist):
    if len(alist) > 1:
        mid = len(alist) // 2 # integer division
        lefthalf = alist[:mid]
        righthalf = alist[mid:]
        mergeSort(lefthalf)
        mergeSort(righthalf)
```

As you can see from the above code, whenever the algorithm recurses, only half of the list is passed on. Meaning that it is doing only half the work. And since it halves the list every recursion regardless of the state of the list (ordered or not), the time complexity for this part of the code is O(logn) for all cases.

###Where does the n come from?

The n comes frome the 3 while loops present in the code: 

```python
while i < len(lefthalf) and j < len(righthalf):
        	if lefthalf[i] <= righthalf[j]:
        		alist[k]=lefthalf[i]
        		i=i+1
        	else:
        		alist[k]=righthalf[j]
        		j=j+1
        	k=k+1

        while i < len(lefthalf):
        	alist[k]=lefthalf[i]
        	i=i+1
        	k=k+1

        while j < len(righthalf):
        	alist[k]=righthalf[j]
        	j=j+1
        	k=k+1

```

The while loops iterate over half of the list n times, thus where the n comes from.  And due to the conditions given to the while loops, every time the algorithm recurses, only one while loop will trigger, preventing the time complexity from becoming O(n^2) or O(n^3). Therefore, when you combine the time complexity from the recursion and the time complexity from while loops, you will get O(nlogn).